{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90921cfa",
   "metadata": {},
   "source": [
    "![ga4](https://www.google-analytics.com/collect?v=2&tid=G-6VDTYWLKX6&cid=1&en=page_view&sid=1&dl=statmike%2Fvertex-ai-mlops%2F08+-+R%2Fdepricated&dt=08b+Training+Job+-+Vertex+AI+Custom+Model+-+R+-+Training+Pipeline+With+Custom+Container.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/08%20-%20R/depricated/08b%20Training%20Job%20-%20Vertex%20AI%20Custom%20Model%20-%20R%20-%20Training%20Pipeline%20With%20Custom%20Container.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A//raw.githubusercontent.com/statmike/vertex-ai-mlops/main/08%20-%20R/depricated/08b%20Training%20Job%20-%20Vertex%20AI%20Custom%20Model%20-%20R%20-%20Training%20Pipeline%20With%20Custom%20Container.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/08%20-%20R/depricated/08b%20Training%20Job%20-%20Vertex%20AI%20Custom%20Model%20-%20R%20-%20Training%20Pipeline%20With%20Custom%20Container.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A//raw.githubusercontent.com/statmike/vertex-ai-mlops/main/08%20-%20R/depricated/08b%20Training%20Job%20-%20Vertex%20AI%20Custom%20Model%20-%20R%20-%20Training%20Pipeline%20With%20Custom%20Container.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ea515a-03df-4412-abd3-820fd69dee05",
   "metadata": {},
   "source": [
    "# 08b Training Job - Vertex AI > Training > Training Pipelines - With Custom Container\n",
    "\n",
    "**IN ACTIVE DEVELOPMENT - NOT COMPLETE**\n",
    "\n",
    "Dev Notes:\n",
    "- Python Kernel\n",
    "- Orchestrates Vertex AI Services Sequentially\n",
    "\n",
    "Workflow:\n",
    "- code to script\n",
    "- script to container: training and serving in one\n",
    "- training pipeline job\n",
    "- model to Vertex AI Model Registry\n",
    "- deploy model to endpoint for online predictions\n",
    "- batch prediction job with Vertex AI\n",
    "\n",
    "Next Steps:\n",
    "- Pipeline to conduct steps\n",
    "- use [reticulate](https://rstudio.github.io/reticulate/) for an R centric workflow\n",
    "    \n",
    "**Prerequisites:**\n",
    "- [08b Script - Vertex AI Custom Model - R - Notebook to Script](08b%20Script%20-%20Vertex%20AI%20Custom%20Model%20-%20R%20-%20Notebook%20to%20Script.ipynb)\n",
    "    \n",
    "**Resources:**\n",
    "- https://cloud.google.com/blog/products/ai-machine-learning/train-and-deploy-ml-models-with-r-and-plumber-on-vertex-ai\n",
    "- https://cloud.google.com/vertex-ai/docs/workbench/user-managed/use-r-bigquery\n",
    "- https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b23e63-6a03-4b11-839e-5a2a9ea0ef6e",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d2426-f159-4d70-930b-0865e123ba9d",
   "metadata": {},
   "source": [
    "### Package Installs (if needed)\n",
    "\n",
    "This notebook uses the Python Clients for\n",
    "- Google Service Usage\n",
    "    - to enable APIs (Artifact Registry and Cloud Build)\n",
    "- Artifact Registry\n",
    "    - to create repositories for Python packages and Docker containers\n",
    "- Cloud Build\n",
    "    - To build custom Docker containers\n",
    "\n",
    "The cells below check to see if the required Python libraries are installed.  If any are not it will print a message to do the install with the associated pip command to use.  These installs must be completed before continuing this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f4a2cfa5-76a8-4cf7-a7dd-77a9406a3ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.cloud.service_usage_v1\n",
    "except ImportError:\n",
    "    print('You need to pip install google-cloud-service-usage')\n",
    "    !pip install google-cloud-service-usage -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "474394ea-08ea-4327-b287-1c5c84108b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.cloud.artifactregistry_v1\n",
    "except ImportError:\n",
    "    print('You need to pip install google-cloud-artifact-registry')\n",
    "    !pip install google-cloud-artifact-registry -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "83c8ceb7-ad0e-438b-8191-8568eec8a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.cloud.devtools.cloudbuild\n",
    "except ImportError:\n",
    "    print('You need to pip install google-cloud-build')\n",
    "    !pip install google-cloud-build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e76d56-99cc-4f29-98c1-edaf6bf569d0",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d854258-fc2d-4dce-b65f-aaa666917230",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e7f9f258-f67d-4b6d-998b-09ba384974ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9126be55-8d72-4012-9ece-8d2f52a85ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = '08b'\n",
    "SERIES = '08'\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud'\n",
    "BQ_TABLE = 'fraud_prepped'\n",
    "\n",
    "# Resources\n",
    "TRAIN_COMPUTE = 'n1-standard-4'\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1341dda-9153-457e-be08-20a95c0abe86",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a2120141-22d6-49c3-9b28-25f103b08b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "import os, shutil, glob\n",
    "import pkg_resources\n",
    "from IPython.display import Markdown as md\n",
    "from google.cloud import service_usage_v1\n",
    "from google.cloud.devtools import cloudbuild_v1\n",
    "from google.cloud import artifactregistry_v1\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e46d467-96e2-446a-84f1-16e181210000",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5c00fa76-a5ab-4c96-bb4c-a34a37ecf615",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bq = bigquery.Client()\n",
    "gcs = storage.Client()\n",
    "su_client = service_usage_v1.ServiceUsageClient()\n",
    "ar_client = artifactregistry_v1.ArtifactRegistryClient()\n",
    "cb_client = cloudbuild_v1.CloudBuildClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcc3615-1571-4e65-b3d1-293cc09112bf",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e79c9215-4558-4e28-af76-4373b4929fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = PROJECT_ID\n",
    "URI = f\"gs://{BUCKET}/{SERIES}/{EXPERIMENT}\"\n",
    "DIR = f\"temp/{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "dcc5c459-13db-42df-8366-8cecd7474485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f54c8-7364-46c7-b8db-feb922de4631",
   "metadata": {},
   "source": [
    "List the service accounts current roles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "85e56b6c-36b2-45ba-9aa0-baf887c58636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE\n",
      "roles/bigquery.admin\n",
      "roles/owner\n",
      "roles/run.admin\n",
      "roles/storage.objectAdmin\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" --format='table(bindings.role)' --flatten=\"bindings[].members\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f63bb4a-be89-41dc-81e4-71ec5d538861",
   "metadata": {},
   "source": [
    ">Note: If the resulting list is missing [roles/storage.objectAdmin](https://cloud.google.com/storage/docs/access-control/iam-roles) then [revisit the setup notebook](../00%20-%20Setup/00%20-%20Environment%20Setup.ipynb#permissions) and add this permission to the service account with the provided instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f2704-1aa0-4921-925b-3e2859de5563",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "64f7a268-9d00-47aa-9a00-362650e8add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1040a55-82cb-4c34-a3ee-7af94d07e73e",
   "metadata": {},
   "source": [
    "Experiment Tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5a86cee3-c059-48de-8a43-ccf99ff0fdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMEWORK = 'r'\n",
    "TASK = 'classification'\n",
    "MODEL_TYPE = 'logistic_regression'\n",
    "EXPERIMENT_NAME = f'experiment-{SERIES}-{EXPERIMENT}-{FRAMEWORK}-{TASK}-{MODEL_TYPE}'\n",
    "RUN_NAME = f'run-{TIMESTAMP}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5af49-1e70-4349-a740-7989ea528e24",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Enable APIs\n",
    "\n",
    "Using Cloud Build and Artifact Registry requires enabling these APIs for the Google Cloud Project.\n",
    "\n",
    "Options for enabeling these.  In this notebook option 2 is used.\n",
    " 1. Use the APIs & Services page in the console: https://console.cloud.google.com/apis\n",
    "     - `+ Enable APIs and Services`\n",
    "     - Search for Cloud Build and Enable\n",
    "     - Search for Artifact Registry and Enable\n",
    " 2. Use [Google Service Usage](https://cloud.google.com/service-usage/docs) API from Python\n",
    "     - [Python Client For Service Usage](https://github.com/googleapis/python-service-usage)\n",
    "     - [Python Client Library Documentation](https://cloud.google.com/python/docs/reference/serviceusage/latest)\n",
    "     \n",
    "The following code cells use the Service Usage Client to:\n",
    "- get the state of the service\n",
    "- if 'DISABLED':\n",
    "    - Try enabling the service and return the state after trying\n",
    "- if 'ENABLED' print the state for confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941628d-6ddf-4e3c-ba5d-8cea56ec6780",
   "metadata": {},
   "source": [
    "#### Artifact Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "57c9e824-ae7a-4fac-99e7-2e4d4bcfa3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifact Registry already enabled for project: statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "artifactregistry = su_client.get_service(\n",
    "    request = service_usage_v1.GetServiceRequest(\n",
    "        name = f'projects/{PROJECT_ID}/services/artifactregistry.googleapis.com'\n",
    "    )\n",
    ").state.name\n",
    "\n",
    "\n",
    "if artifactregistry == 'DISABLED':\n",
    "    print(f'Artifact Registry is currently {artifactregistry} for project: {PROJECT_ID}')\n",
    "    print(f'Trying to Enable...')\n",
    "    operation = su_client.enable_service(\n",
    "        request = service_usage_v1.EnableServiceRequest(\n",
    "            name = f'projects/{PROJECT_ID}/services/artifactregistry.googleapis.com'\n",
    "        )\n",
    "    )\n",
    "    response = operation.result()\n",
    "    if response.service.state.name == 'ENABLED':\n",
    "        print(f'Artifact Registry is now enabled for project: {PROJECT_ID}')\n",
    "    else:\n",
    "        print(response)\n",
    "else:\n",
    "    print(f'Artifact Registry already enabled for project: {PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3f6bf-c4ec-4315-84e7-5e2f473d5e4d",
   "metadata": {},
   "source": [
    "#### Cloud Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "de495fb8-0ef8-41bc-b028-d544911a373c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud Build already enabled for project: statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "cloudbuild = su_client.get_service(\n",
    "    request = service_usage_v1.GetServiceRequest(\n",
    "        name = f'projects/{PROJECT_ID}/services/cloudbuild.googleapis.com'\n",
    "    )\n",
    ").state.name\n",
    "\n",
    "\n",
    "if cloudbuild == 'DISABLED':\n",
    "    print(f'Cloud Build is currently {cloudbuild} for project: {PROJECT_ID}')\n",
    "    print(f'Trying to Enable...')\n",
    "    operation = su_client.enable_service(\n",
    "        request = service_usage_v1.EnableServiceRequest(\n",
    "            name = f'projects/{PROJECT_ID}/services/cloudbuild.googleapis.com'\n",
    "        )\n",
    "    )\n",
    "    response = operation.result()\n",
    "    if response.service.state.name == 'ENABLED':\n",
    "        print(f'Cloud Build is now enabled for project: {PROJECT_ID}')\n",
    "    else:\n",
    "        print(response)\n",
    "else:\n",
    "    print(f'Cloud Build already enabled for project: {PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7edfb9b-c4ba-446c-b7f1-31f2152df7d0",
   "metadata": {},
   "source": [
    "---\n",
    "## Training & Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff3cf5-6752-4a17-8de6-98d7b3aa7c18",
   "metadata": {},
   "source": [
    "### R Script for Training\n",
    "\n",
    "This notebook trains the same R model from [08 - Vertex AI Custom Model - R - in Notebook](./08%20-%20Vertex%20AI%20Custom%20Model%20-%20R%20-%20in%20Notebook.ipynb) by first modifying and saving the training code to an R script as shown in [08 - Vertex Ai Custom Model - R - Notebook to Script](08%20-%20Vertex%20AI%20Custom%20Model%20-%20R%20-%20Notebook%20to%20Script.ipynb) which stores the script in [`./code/train.R`](./code/train.R).\n",
    "\n",
    "**Review the script:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0c7959c5-1bb0-40e8-9dbc-d4212b3b52f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```R\n",
       "\n",
       "\n",
       "# library import\n",
       "library(bigrquery)\n",
       "library(dplyr)\n",
       "\n",
       "# inputs\n",
       "args <- commandArgs(trailingOnly = TRUE)\n",
       "project_id <- args[1]\n",
       "region <- args[2]\n",
       "experiment <- args[3]\n",
       "series <- args[4]\n",
       "bq_project <- args[5]\n",
       "bq_dataset <- args[6]\n",
       "bq_table <- args[7]\n",
       "var_target <- args[8]\n",
       "var_omit <- args[9]\n",
       "\n",
       "# data source\n",
       "get_data <- function(s){\n",
       "    query = sprintf('SELECT * EXCEPT(%s, splits) FROM `%s.%s.%s` WHERE splits = \"%s\"', var_omit, bq_project, bq_dataset, bq_table, s)\n",
       "    table <- bq_project_query(bq_project, query)\n",
       "    ds <- bq_table_download(table)\n",
       "    return(ds)\n",
       "}\n",
       "train <- get_data(\"TRAIN\")\n",
       "test <- get_data(\"TEST\")\n",
       "\n",
       "# logistic regression model\n",
       "model <- glm(\n",
       "    Class ~ .,\n",
       "    data = train,\n",
       "    family = binomial)\n",
       "\n",
       "# predictions for evaluation\n",
       "preds <- predict(model, test, type = \"response\")\n",
       "\n",
       "# evaluate\n",
       "actual <- test[, var_target]\n",
       "names(actual) <- 'actual'\n",
       "pred <- tibble(round(preds))\n",
       "names(pred) <- 'pred'\n",
       "results <- cbind(actual, pred)\n",
       "cm <- table(results)\n",
       "\n",
       "# save model to file\n",
       "saveRDS(model, \"model.rds\")\n",
       "\n",
       "path <- sub('gs://', '/gcs/', Sys.getenv('AIP_MODEL_DIR'))\n",
       "#saveRDS(\n",
       "#    model,\n",
       "#    sprintf('%smodel.rds', path)\n",
       "#)\n",
       "\n",
       "# use Vertex AI Training Pre-Defined Environment Variables to Write to GCS\n",
       "#system2('gsutil', c('cp', 'model.rds', Sys.getenv('AIP_MODEL_DIR')))\n",
       "system2('cp', c('model.rds', path))\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCRIPT_PATH = './code/train.R'\n",
    "\n",
    "with open(SCRIPT_PATH, 'r') as file:\n",
    "    data = file.read()\n",
    "md(f\"```R\\n\\n{data}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c40e87-ec43-435d-a3c5-1ac64e268f6f",
   "metadata": {},
   "source": [
    "Make a copy of the script in the notebooks temp folder and append code for saving to GCS model directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e42e4f07-e9b3-4c9f-829e-433977cec8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./temp/08b/train.R'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copyfile(SCRIPT_PATH, f'./{DIR}/train.R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e86bed83-8743-42c8-be98-cd9b380e6014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to ./temp/08b/train.R\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a ./{DIR}/train.R\n",
    "\n",
    "# use Vertex AI Training Pre-Defined Environment Variables to Write to GCS\n",
    "system2('gsutil', c('cp', 'model.rds', Sys.getenv('AIP_MODEL_DIR')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5e4fd6-d155-4799-b2e4-dbbd00dc7149",
   "metadata": {},
   "source": [
    "### R Script for Serving - With Vertex AI\n",
    "\n",
    "To serve the model, another script that uses [plumber](https://www.rplumber.io/) is created:\n",
    "\n",
    "**Create the script:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8139e2f4-1e9c-4391-978b-740fb5b69d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./temp/08b/serve.R\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./{DIR}/serve.R\n",
    "\n",
    "# library import\n",
    "library(plumber)\n",
    "\n",
    "# use Vertex AI Training Pre-Defined Environment Variables to Read from GCS\n",
    "Sys.getenv()\n",
    "system2('gsutil', c('cp', '-r', Sys.getenv('AIP_STORAGE_URI'), '.'))\n",
    "system(\"du -a .\")\n",
    "\n",
    "# import model\n",
    "model <- readRDS('artifacts/model.rds')\n",
    "\n",
    "# prediction route function\n",
    "predict_route <- function(req, res){\n",
    "    print(\"Processing Prediction Request...\")\n",
    "    df <- as.data.frame(req$body$instances)\n",
    "    preds <- predict(model, df, type = \"response\")\n",
    "    return(list(predictions = preds))\n",
    "}\n",
    "\n",
    "# serving\n",
    "print(\"Start Serving Process...\")\n",
    "pr() %>%\n",
    "    pr_get(Sys.getenv(\"AIP_HEALTH_ROUTE\"), function() \"200 OK\") %>%\n",
    "    pr_post(Sys.getenv(\"AIP_PREDICT_ROUTE\"), predict_route) %>%\n",
    "    pr_run(host = \"0.0.0.0\", port=as.integer(Sys.getenv(\"AIP_HTTP_PORT\", 8080)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b355b167-4918-4188-90f3-501e9a393e6b",
   "metadata": {},
   "source": [
    "### R Script for Serving - With Google Cloud Run\n",
    "\n",
    "To serve the model, another script that uses [plumber](https://www.rplumber.io/) is created:\n",
    "\n",
    "**Create the script:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0285048d-c01e-48eb-8169-6ee8907c9391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20221108123731'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIMESTAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4a7b80e8-5a67-481a-b6b2-94b5f98bfd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./temp/08b/serve_cloudrun.R\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./{DIR}/serve_cloudrun.R\n",
    "\n",
    "# library import\n",
    "library(plumber)\n",
    "\n",
    "# use Vertex AI Training Pre-Defined Environment Variables to Read from GCS\n",
    "Sys.getenv()\n",
    "#system2('gsutil', c('cp', '-r', Sys.getenv('AIP_STORAGE_URI'), '.'))\n",
    "system2('gsutil', c('cp', 'gs://statmike-mlops-349915/08/08b/models/20221107235510/model/model.rds', '.'))\n",
    "system(\"du -a .\")\n",
    "\n",
    "# import model\n",
    "model <- readRDS('model.rds')\n",
    "\n",
    "# prediction route function\n",
    "predict_route <- function(req, res){\n",
    "    print(\"Processing Prediction Request...\")\n",
    "    df <- as.data.frame(req$body$instances)\n",
    "    preds <- predict(model, df, type = \"response\")\n",
    "    return(list(predictions = preds))\n",
    "}\n",
    "\n",
    "# serving\n",
    "print(\"Start Serving Process...\")\n",
    "pr() %>%\n",
    "    #pr_get(Sys.getenv(\"AIP_HEALTH_ROUTE\"), function() \"200 OK\") %>%\n",
    "    #pr_post(Sys.getenv(\"AIP_PREDICT_ROUTE\"), predict_route) %>%\n",
    "    #pr_run(host = \"0.0.0.0\", port=as.integer(Sys.getenv(\"AIP_HTTP_PORT\", 8080)))\n",
    "    pr_post(\"/predict\", predict_route) %>%\n",
    "    pr_run(host = \"0.0.0.0\", port=8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e84edff-2733-4bc4-9046-c884ae3d8af4",
   "metadata": {},
   "source": [
    "### Creating a Custom Container with Cloud Build\n",
    "\n",
    "Cloud Build creates and manages the build on GCP.  The API creates a build by providing:\n",
    "- location of the source\n",
    "- instructions\n",
    "- location to store the built artifacts\n",
    "\n",
    "The instruction part of Cloud Build has options:\n",
    "- Dockerfile\n",
    "- Build Config file (YAML or JSON)\n",
    "- Cloud Native Buildpacks\n",
    "\n",
    "This notebook uses the approach of using the Python Client for Cloud Build and not referencing any local files.  For that reason, the first step is creating a Dockerfile for the workflow and storing it in GCS. The next step is running Cloud Build and using the client to specify the Build config rather than a config file.  The steps of the build config start with getting the code (git clone, or copy from GCS) and copying the Dockerfile.  \n",
    "\n",
    "There are many workflows for creating containers with ML training code.  Many of the most common ones are explored in the tips notebook [Python Custom Containers](../Tips/Python%20Custom%20Containers.ipynb).  The method used here is the simplest - copy the training code directly into the container.  The other methods include packaging the training code as a Python Distribution and using `pip install` in from GCS, GitHub and even Artifact Registry as a private repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1d9715-b173-45a0-9c81-07d06931d214",
   "metadata": {},
   "source": [
    "#### Create the Dockerfile\n",
    "A basic dockerfile thats take the base image and copies the code in and add additional installs:\n",
    "\n",
    "**Choose a BASE Image**\n",
    "\n",
    "Here the base image is a pre-built deep-learning container from Google Cloud with the latest updates for `R` version 4.1.  Other sources for containers can be found here:\n",
    "- [Deep Learning Containers](https://cloud.google.com/deep-learning-containers/docs/choosing-container)\n",
    "    - list these with `gcloud container images list --repository=\"gcr.io/deeplearning-platform-release\"`\n",
    "- [Vertex AI Pre-Built Containers for Custom Training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers)\n",
    "    - list these with `gcloud container images list --repository=\"us-docker.pkg.dev/vertex-ai/training\"`\n",
    "- [Vertex AI Pre-Built Containers for Prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers)\n",
    "    - list these with `gcloud container images list --repository=\"us-docker.pkg.dev/vertex-ai/prediction\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f7cbba22-9a30-49b7-9f26-be61455aa635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./temp/08b/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./{DIR}/Dockerfile\n",
    "FROM gcr.io/deeplearning-platform-release/r-cpu.4-1:latest\n",
    "\n",
    "WORKDIR /root\n",
    "ENV PORT=8080\n",
    "# copy code into /code folder\n",
    "COPY ./*.R ./code/\n",
    "\n",
    "RUN apt-get update\n",
    "RUN apt-get install gfortran -yy\n",
    "RUN R -e 'install.packages(c(\"plumber\"))'\n",
    "\n",
    "EXPOSE 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e1240b-8dd0-4a69-baf3-2463ac066b81",
   "metadata": {},
   "source": [
    "#### Store Resources in Cloud Storage\n",
    "\n",
    "Copy from local folder (`DIR`) to GCS at the path `SERIES/EXPERIMENT/models/TIMESTAMP`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3c60bbd7-4f9b-49b0-890b-4a6d218a9fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile  serve.R  serve_cloudrun.R  train.R\n"
     ]
    }
   ],
   "source": [
    "!ls {DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "46e23aa6-2a6d-426c-bc63-741c79a0f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = gcs.lookup_bucket(PROJECT_ID)\n",
    "SOURCEPATH = f'{SERIES}/{EXPERIMENT}/models/{TIMESTAMP}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d2b4366a-7d27-49a9-b1d7-dc0aebbd1c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.R\n",
      "serve.R\n",
      "serve_cloudrun.R\n",
      "Dockerfile\n"
     ]
    }
   ],
   "source": [
    "for file in [f for f in os.listdir(DIR) if not f.startswith('.')]:\n",
    "    print(file)\n",
    "    blob = bucket.blob(f'{SOURCEPATH}/code/{file}')\n",
    "    blob.upload_from_filename(f'{DIR}/{file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c24d32d8-2fed-4b21-859f-0f80d5eca80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Blob: statmike-mlops-349915, 08/08b/models/20221108123731/code/Dockerfile, 1667911057457904>,\n",
       " <Blob: statmike-mlops-349915, 08/08b/models/20221108123731/code/serve.R, 1667911057321247>,\n",
       " <Blob: statmike-mlops-349915, 08/08b/models/20221108123731/code/serve_cloudrun.R, 1667911057372443>,\n",
       " <Blob: statmike-mlops-349915, 08/08b/models/20221108123731/code/train.R, 1667911057255213>]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bucket.list_blobs(prefix = f'{SOURCEPATH}/code'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ea615428-46bc-4477-b11f-afba7a77c5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the bucket directly here:\n",
      "https://console.cloud.google.com/storage/browser/statmike-mlops-349915/08/08b/models/20221108123731/code;tab=objects&project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f\"View the bucket directly here:\\nhttps://console.cloud.google.com/storage/browser/{PROJECT_ID}/{SOURCEPATH}/code;tab=objects&project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe928aa4-a6aa-4ae7-a8e9-8b410762c433",
   "metadata": {},
   "source": [
    "#### Setup Artifact Registry\n",
    "\n",
    "Artifact registry organizes artifacts with repositories.  Each repository contains packages and is designated to hold a partifcular format of package: Docker images, Python Packages and [others](https://cloud.google.com/artifact-registry/docs/supported-formats#package)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09ed5f6-1d69-4fdb-83b9-c782d884d30a",
   "metadata": {},
   "source": [
    "##### List Repositories\n",
    "\n",
    "This may be empty if no repositories have been created for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "be78242d-ed78-410f-9942-485e72114418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-docker\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-python\n"
     ]
    }
   ],
   "source": [
    "for repo in ar_client.list_repositories(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n",
    "    print(repo.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4563bd94-37e1-4b40-a023-1ce4d2ecfe05",
   "metadata": {},
   "source": [
    "#### Create Docker Image Repository\n",
    "\n",
    "Create an Artifact Registry Repository to hold Docker Images created by this notebook.  First, check to see if it is already created by a previous run and retrieve it if it has.  Otherwise, create!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5f4399f2-28f3-44af-af27-2f0a0965623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved existing repo: projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "docker_repo = None\n",
    "for repo in ar_client.list_repositories(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n",
    "    if repo.name.endswith(PROJECT_ID):\n",
    "        docker_repo = repo\n",
    "        print(f'Retrieved existing repo: {docker_repo.name}')\n",
    "\n",
    "if not docker_repo:\n",
    "    operation = ar_client.create_repository(\n",
    "        request = artifactregistry_v1.CreateRepositoryRequest(\n",
    "            parent = f'projects/{PROJECT_ID}/locations/{REGION}',\n",
    "            repository_id = f'{PROJECT_ID}',\n",
    "            repository = artifactregistry_v1.Repository(\n",
    "                description = f'A repository for the {PROJECT_ID} project that holds docker images.',\n",
    "                name = f'{PROJECT_ID}',\n",
    "                format_ = artifactregistry_v1.Repository.Format.DOCKER,\n",
    "                labels = {'series': SERIES, 'experiment': EXPERIMENT}\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print('Creating Repository ...')\n",
    "    docker_repo = operation.result()\n",
    "    print(f'Completed creating repo: {docker_repo.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9d2d6bcb-564a-4ce3-92b0-4aa90db6ea7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCKER projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(docker_repo.format_.name, docker_repo.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f41f170c-3c6e-4c01-9b30-e444862915c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPOSITORY = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{docker_repo.name.split('/')[-1]}\"\n",
    "REPOSITORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3fb50325-3986-4e30-bd88-903662da59d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the repository directly in the console here:\n",
      "https://console.cloud.google.com/artifacts/docker/statmike-mlops-349915/us-central1/statmike-mlops-349915?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f'View the repository directly in the console here:\\nhttps://console.cloud.google.com/artifacts/docker/{PROJECT_ID}/{REGION}/{PROJECT_ID}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0142cfef-3a9f-4b09-b241-a89e36a736db",
   "metadata": {},
   "source": [
    "#### Build Custom Container\n",
    "Use the Cloud Build client to construct and run the build instructions.  Here the files collected in GCS are copied to the build instance, then the Docker build in run in the folder with the `Dockerfile`.  The resulting image is pushed to Artifact Registry (setup above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ea41e5d7-79c4-43f9-bfe9-29077e5bc5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the build config with empty list of steps - these will be added sequentially\n",
    "build = cloudbuild_v1.Build(\n",
    "    steps = []\n",
    ")\n",
    "# retrieve the source\n",
    "build.steps.append(\n",
    "    {\n",
    "        'name': 'gcr.io/cloud-builders/gsutil',\n",
    "        'args': ['cp', '-r', f'gs://{PROJECT_ID}/{SOURCEPATH}/code/*', '/workspace']\n",
    "    }\n",
    ")\n",
    "# docker build\n",
    "build.steps.append(\n",
    "    {\n",
    "        'name': 'gcr.io/cloud-builders/docker',\n",
    "        'args': ['build', '-t', f'{REPOSITORY}/{EXPERIMENT}', '/workspace']\n",
    "    }    \n",
    ")\n",
    "# docker push\n",
    "build.images = [f\"{REPOSITORY}/{EXPERIMENT}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b3317c94-4f2e-4469-943b-9e77cf922e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "steps {\n",
       "  name: \"gcr.io/cloud-builders/gsutil\"\n",
       "  args: \"cp\"\n",
       "  args: \"-r\"\n",
       "  args: \"gs://statmike-mlops-349915/08/08b/models/20221108123731/code/*\"\n",
       "  args: \"/workspace\"\n",
       "}\n",
       "steps {\n",
       "  name: \"gcr.io/cloud-builders/docker\"\n",
       "  args: \"build\"\n",
       "  args: \"-t\"\n",
       "  args: \"us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/08b\"\n",
       "  args: \"/workspace\"\n",
       "}\n",
       "images: \"us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/08b\""
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6284d793-3425-4721-884d-cec6892a88b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "operation = cb_client.create_build(\n",
    "    project_id = PROJECT_ID,\n",
    "    build = build\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d6f00a84-9d23-4529-a088-25629533fe3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Status.SUCCESS: 3>,\n",
       " images: \"us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915/08b\")"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = operation.result()\n",
    "response.status, response.artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d60548a9-79ad-4f75-af4a-2c520806f39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the Custom Container with Artifact Registry in the Google Cloud Console:\n",
      "https://console.cloud.google.com/artifacts/docker/statmike-mlops-349915/us-central1/statmike-mlops-349915-docker?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f\"Review the Custom Container with Artifact Registry in the Google Cloud Console:\\nhttps://console.cloud.google.com/artifacts/docker/{PROJECT_ID}/{REGION}/{PROJECT_ID}-docker?project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f02643-fe90-42ab-ab42-ced198a1daf7",
   "metadata": {},
   "source": [
    "### Setup Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "67dd3c91-4823-445e-8703-2c130e3af30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMDARGS = [\n",
    "    \"--project_id=\" + PROJECT_ID,\n",
    "    \"--region=\" + REGION,\n",
    "    \"--experiment=\" + EXPERIMENT,\n",
    "    \"--series=\" + SERIES,\n",
    "    \"--bq_project=\" + BQ_PROJECT,\n",
    "    \"--bq_dataset=\" + BQ_DATASET,\n",
    "    \"--bq_table=\" + BQ_TABLE,\n",
    "    \"--var_target=\" + VAR_TARGET,\n",
    "    \"--var_omit=\" + VAR_OMIT,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ef1e00-0de8-4667-960a-ad73cd61f160",
   "metadata": {},
   "source": [
    "R code using `commandArgs()` does not used named parameters so parse `CMDARGS` for the `R` script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e0b87755-3a11-421f-b724-0473f7d62b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['statmike-mlops-349915',\n",
       " 'us-central1',\n",
       " '08b',\n",
       " '08',\n",
       " 'statmike-mlops-349915',\n",
       " 'fraud',\n",
       " 'fraud_prepped',\n",
       " 'Class',\n",
       " 'transaction_id']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMDARGS = [c.split('=')[-1] for c in CMDARGS]\n",
    "CMDARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ac76cf49-06ee-44ec-8090-00664013779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingJob = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name = f'{SERIES}_{EXPERIMENT}_{TIMESTAMP}',\n",
    "    container_uri = f\"{REPOSITORY}/{EXPERIMENT}\",\n",
    "    command = [\"Rscript\", \"./code/train.R\"],\n",
    "    model_serving_container_image_uri = f\"{REPOSITORY}/{EXPERIMENT}\",\n",
    "    model_serving_container_command = [\"Rscript\", \"./code/serve.R\"],\n",
    "    staging_bucket = f\"{URI}/models/{TIMESTAMP}\",\n",
    "    labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bf6289-26fc-4762-9555-5341adff89ce",
   "metadata": {},
   "source": [
    "### Run Training Job AND Upload The Model\n",
    "The training job will automatically upload the model to the Vertex AI Model Registry and return the link to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b3453c91-81d2-4b43-84ca-2e0dd91d97c7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Already in Registry:\n",
      "Loading model as new default version.\n",
      "Training Output directory:\n",
      "gs://statmike-mlops-349915/08/08b/models/20221108123731 \n",
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/544176617010757632?project=1026793852137\n",
      "CustomContainerTrainingJob projects/1026793852137/locations/us-central1/trainingPipelines/544176617010757632 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "View backing custom job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/2874156105477390336?project=1026793852137\n",
      "CustomContainerTrainingJob projects/1026793852137/locations/us-central1/trainingPipelines/544176617010757632 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/1026793852137/locations/us-central1/trainingPipelines/544176617010757632 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/1026793852137/locations/us-central1/trainingPipelines/544176617010757632 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/1026793852137/locations/us-central1/trainingPipelines/544176617010757632 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/1026793852137/locations/us-central1/trainingPipelines/544176617010757632 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob run completed. Resource name: projects/1026793852137/locations/us-central1/trainingPipelines/544176617010757632\n",
      "Model available at projects/1026793852137/locations/us-central1/models/model_08_08b\n"
     ]
    }
   ],
   "source": [
    "modelmatch = aiplatform.Model.list(filter = f'display_name={SERIES}_{EXPERIMENT} AND labels.series={SERIES} AND labels.experiment={EXPERIMENT}')\n",
    "\n",
    "upload_model = True\n",
    "if modelmatch:\n",
    "    print(\"Model Already in Registry:\")\n",
    "    if RUN_NAME in modelmatch[0].version_aliases:\n",
    "        print(\"This version already loaded, no action taken.\")\n",
    "        upload_model = False\n",
    "        model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "    else:\n",
    "        print('Loading model as new default version.')\n",
    "        #parent_model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "        parent_model = modelmatch[0].resource_name\n",
    "else:\n",
    "    print('This is a new model, adding to model registry as version 1')\n",
    "    parent_model = ''\n",
    "\n",
    "if upload_model:\n",
    "    model = trainingJob.run(\n",
    "        model_display_name = f'{SERIES}_{EXPERIMENT}',\n",
    "        model_labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'},\n",
    "        model_id = f'model_{SERIES}_{EXPERIMENT}',\n",
    "        parent_model = parent_model,\n",
    "        is_default_version = True,\n",
    "        model_version_aliases = [RUN_NAME],\n",
    "        model_version_description = RUN_NAME,\n",
    "        base_output_dir = f\"{URI}/models/{TIMESTAMP}\",\n",
    "        service_account = SERVICE_ACCOUNT,\n",
    "        args = CMDARGS,\n",
    "        replica_count = 1,\n",
    "        machine_type = TRAIN_COMPUTE,\n",
    "        accelerator_count = 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d56ab8-9495-4b15-8daa-e5e0104398fc",
   "metadata": {},
   "source": [
    "Get the backing Custom Job for the Training Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7d2a7c97-f99c-420a-90af-50a0d9dc3cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clientPL = aiplatform.gapic.PipelineServiceClient(client_options = {'api_endpoint': f'{REGION}-aiplatform.googleapis.com'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8cf4b02a-053c-4aff-b06d-92a41d934404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf.json_format import MessageToDict\n",
    "\n",
    "backingCustomJob = MessageToDict(clientPL.get_training_pipeline(name = trainingJob.resource_name)._pb)['trainingTaskMetadata']['backingCustomJob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4e605d5f-6e5c-4b34-a0e1-82e438e5d59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('projects/1026793852137/locations/us-central1/customJobs/2874156105477390336',\n",
       " '08_08b_20221108123731-custom-job')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customJob = aiplatform.CustomJob.get(backingCustomJob)\n",
    "customJob.resource_name, customJob.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15ff790-091a-4d70-bbe5-be2286656698",
   "metadata": {},
   "source": [
    "Create hyperlinks to job and tensorboard here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4c0dcbef-1fcf-4476-b78a-56b18cbc8566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the Training Pipeline here:\n",
      "https://console.cloud.google.com/vertex-ai/training/training-pipelines?project=statmike-mlops-349915\n",
      "Review the Custom Job here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/training/2874156105477390336/cpu?cloudshell=false&project=statmike-mlops-349915\n",
      "Review the model in the Vertex AI Model Registry:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/models/model_08_08b?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "job_link = f\"https://console.cloud.google.com/vertex-ai/locations/{REGION}/training/{customJob.resource_name.split('/')[-1]}/cpu?cloudshell=false&project={PROJECT_ID}\"\n",
    "\n",
    "print(f'Review the Training Pipeline here:\\nhttps://console.cloud.google.com/vertex-ai/training/training-pipelines?project={PROJECT_ID}')\n",
    "print(f'Review the Custom Job here:\\n{job_link}')\n",
    "print(f'Review the model in the Vertex AI Model Registry:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/models/{model.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c38dd4-2974-48da-a061-61211da03274",
   "metadata": {},
   "source": [
    "---\n",
    "## Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f3bc28-0f17-47b5-adc8-5bb5e6b15377",
   "metadata": {},
   "source": [
    "### Create/Retrieve The Endpoint For This Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5ca3e46b-9fa1-478f-9fcc-18908541704e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Exists: projects/1026793852137/locations/us-central1/endpoints/1178329019301494784\n",
      "Review the Endpoint in the Console:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/endpoints/1178329019301494784?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "endpoints = aiplatform.Endpoint.list(filter = f\"labels.series={SERIES}\")\n",
    "if endpoints:\n",
    "    endpoint = endpoints[0]\n",
    "    print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n",
    "else:\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "        display_name = f\"{SERIES}\",\n",
    "        labels = {'series' : f\"{SERIES}\"}    \n",
    "    )\n",
    "    print(f\"Endpoint Created: {endpoint.resource_name}\")\n",
    "    \n",
    "print(f'Review the Endpoint in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/endpoints/{endpoint.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ff509655-96cb-4828-9918-ac1d0e758e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'08'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b4b6a389-50f3-42db-bae1-21f73b8c1965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'8791435490952740864': 100}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "187e3d84-3232-49f6-a0ca-bc84083f60a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_models = endpoint.list_models()\n",
    "#deployed_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31748391-51ef-4f91-8281-35dd402572f6",
   "metadata": {},
   "source": [
    "### Deploy Model To Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4442b22a-6c5f-49a5-b53d-a3b39c2ba662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model with 100% of traffic...\n",
      "Deploying Model projects/1026793852137/locations/us-central1/models/model_08_08b to Endpoint : projects/1026793852137/locations/us-central1/endpoints/1178329019301494784\n",
      "Deploy Endpoint model backing LRO: projects/1026793852137/locations/us-central1/endpoints/1178329019301494784/operations/5433849480229158912\n",
      "Endpoint model deployed. Resource name: projects/1026793852137/locations/us-central1/endpoints/1178329019301494784\n"
     ]
    }
   ],
   "source": [
    "print(f'Deploying model with 100% of traffic...')\n",
    "endpoint.deploy(\n",
    "    model = model,\n",
    "    deployed_model_display_name = model.display_name,\n",
    "    traffic_percentage = 100,\n",
    "    machine_type = DEPLOY_COMPUTE,\n",
    "    min_replica_count = 1,\n",
    "    max_replica_count = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc92b87-4ba6-4642-b543-6585ca2bf0a1",
   "metadata": {},
   "source": [
    "### Remove Deployed Models without Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "80cbb31b-7172-4a5e-be4f-e570d3327241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 08_08b with version 4 has traffic = 100\n",
      "Undeploying Endpoint model: projects/1026793852137/locations/us-central1/endpoints/1178329019301494784\n",
      "Undeploy Endpoint model backing LRO: projects/1026793852137/locations/us-central1/endpoints/1178329019301494784/operations/1608041596777922560\n",
      "Endpoint model undeployed. Resource name: projects/1026793852137/locations/us-central1/endpoints/1178329019301494784\n",
      "Undeploying 08_08b_gcs with version 1 because it has no traffic.\n"
     ]
    }
   ],
   "source": [
    "for deployed_model in endpoint.list_models():\n",
    "    if deployed_model.id in endpoint.traffic_split:\n",
    "        print(f\"Model {deployed_model.display_name} with version {deployed_model.model_version_id} has traffic = {endpoint.traffic_split[deployed_model.id]}\")\n",
    "    else:\n",
    "        endpoint.undeploy(deployed_model_id = deployed_model.id)\n",
    "        print(f\"Undeploying {deployed_model.display_name} with version {deployed_model.model_version_id} because it has no traffic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5baf1186-a64e-4022-8f95-21765bceeb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'6706831813433622528': 100}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1e0cbcd9-fb38-426f-ac61-6e717f0ad9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#endpoint.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a02832-0857-4234-b846-71a90c9374cb",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1a810-c7a6-4fe8-b67f-fedfa1d7d9b5",
   "metadata": {},
   "source": [
    "### Prepare a record for prediction: instance and parameters lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "19c7f0db-e970-40de-a558-74350b78c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bq.query(query = f\"SELECT * FROM {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE} WHERE splits='TEST' LIMIT 10\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "400854ed-f8c5-4142-a73f-85168bca360b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35337</td>\n",
       "      <td>1.092844</td>\n",
       "      <td>-0.013230</td>\n",
       "      <td>1.359829</td>\n",
       "      <td>2.731537</td>\n",
       "      <td>-0.707357</td>\n",
       "      <td>0.873837</td>\n",
       "      <td>-0.796130</td>\n",
       "      <td>0.437707</td>\n",
       "      <td>0.396770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167647</td>\n",
       "      <td>0.027557</td>\n",
       "      <td>0.592115</td>\n",
       "      <td>0.219695</td>\n",
       "      <td>0.036970</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>a1b10547-d270-48c0-b902-7a0f735dadc7</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60481</td>\n",
       "      <td>1.238973</td>\n",
       "      <td>0.035226</td>\n",
       "      <td>0.063003</td>\n",
       "      <td>0.641406</td>\n",
       "      <td>-0.260893</td>\n",
       "      <td>-0.580097</td>\n",
       "      <td>0.049938</td>\n",
       "      <td>-0.034733</td>\n",
       "      <td>0.405932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057718</td>\n",
       "      <td>0.104983</td>\n",
       "      <td>0.537987</td>\n",
       "      <td>0.589563</td>\n",
       "      <td>-0.046207</td>\n",
       "      <td>-0.006212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>814c62c8-ade4-47d5-bf83-313b0aafdee5</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139587</td>\n",
       "      <td>1.870539</td>\n",
       "      <td>0.211079</td>\n",
       "      <td>0.224457</td>\n",
       "      <td>3.889486</td>\n",
       "      <td>-0.380177</td>\n",
       "      <td>0.249799</td>\n",
       "      <td>-0.577133</td>\n",
       "      <td>0.179189</td>\n",
       "      <td>-0.120462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180776</td>\n",
       "      <td>-0.060226</td>\n",
       "      <td>-0.228979</td>\n",
       "      <td>0.080827</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>-0.036997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>d08a1bfa-85c5-4f1b-9537-1c5a93e6afd0</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162908</td>\n",
       "      <td>-3.368339</td>\n",
       "      <td>-1.980442</td>\n",
       "      <td>0.153645</td>\n",
       "      <td>-0.159795</td>\n",
       "      <td>3.847169</td>\n",
       "      <td>-3.516873</td>\n",
       "      <td>-1.209398</td>\n",
       "      <td>-0.292122</td>\n",
       "      <td>0.760543</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.171627</td>\n",
       "      <td>0.214333</td>\n",
       "      <td>-0.159652</td>\n",
       "      <td>-0.060883</td>\n",
       "      <td>1.294977</td>\n",
       "      <td>0.120503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>802f3307-8e5a-4475-b795-5d5d8d7d0120</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0   35337  1.092844 -0.013230  1.359829  2.731537 -0.707357  0.873837   \n",
       "1   60481  1.238973  0.035226  0.063003  0.641406 -0.260893 -0.580097   \n",
       "2  139587  1.870539  0.211079  0.224457  3.889486 -0.380177  0.249799   \n",
       "3  162908 -3.368339 -1.980442  0.153645 -0.159795  3.847169 -3.516873   \n",
       "\n",
       "         V7        V8        V9  ...       V23       V24       V25       V26  \\\n",
       "0 -0.796130  0.437707  0.396770  ... -0.167647  0.027557  0.592115  0.219695   \n",
       "1  0.049938 -0.034733  0.405932  ... -0.057718  0.104983  0.537987  0.589563   \n",
       "2 -0.577133  0.179189 -0.120462  ...  0.180776 -0.060226 -0.228979  0.080827   \n",
       "3 -1.209398 -0.292122  0.760543  ... -1.171627  0.214333 -0.159652 -0.060883   \n",
       "\n",
       "        V27       V28  Amount  Class                        transaction_id  \\\n",
       "0  0.036970  0.010984     0.0      0  a1b10547-d270-48c0-b902-7a0f735dadc7   \n",
       "1 -0.046207 -0.006212     0.0      0  814c62c8-ade4-47d5-bf83-313b0aafdee5   \n",
       "2  0.009868 -0.036997     0.0      0  d08a1bfa-85c5-4f1b-9537-1c5a93e6afd0   \n",
       "3  1.294977  0.120503     0.0      0  802f3307-8e5a-4475-b795-5d5d8d7d0120   \n",
       "\n",
       "   splits  \n",
       "0    TEST  \n",
       "1    TEST  \n",
       "2    TEST  \n",
       "3    TEST  \n",
       "\n",
       "[4 rows x 33 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ac8cf5e1-d92f-4c75-b533-32d154efb589",
   "metadata": {},
   "outputs": [],
   "source": [
    "newob = pred[pred.columns[~pred.columns.isin(VAR_OMIT.split()+[VAR_TARGET, 'splits'])]].to_dict(orient='records')[0]\n",
    "#newob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f9b6bb1b-0a82-403e-aaeb-8e9e15830b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Time': 35337,\n",
       " 'V1': 1.0928441854981998,\n",
       " 'V2': -0.0132303486713432,\n",
       " 'V3': 1.35982868199426,\n",
       " 'V4': 2.7315370965921004,\n",
       " 'V5': -0.707357349219652,\n",
       " 'V6': 0.8738370029866129,\n",
       " 'V7': -0.7961301510622031,\n",
       " 'V8': 0.437706509544851,\n",
       " 'V9': 0.39676985012996396,\n",
       " 'V10': 0.587438102569443,\n",
       " 'V11': -0.14979756231827498,\n",
       " 'V12': 0.29514781622888103,\n",
       " 'V13': -1.30382621882143,\n",
       " 'V14': -0.31782283120234495,\n",
       " 'V15': -2.03673231037199,\n",
       " 'V16': 0.376090905274179,\n",
       " 'V17': -0.30040350116459497,\n",
       " 'V18': 0.433799615590844,\n",
       " 'V19': -0.145082264348681,\n",
       " 'V20': -0.240427548108996,\n",
       " 'V21': 0.0376030733329398,\n",
       " 'V22': 0.38002620963091405,\n",
       " 'V23': -0.16764742731151097,\n",
       " 'V24': 0.0275573495476881,\n",
       " 'V25': 0.59211469704354,\n",
       " 'V26': 0.219695164116351,\n",
       " 'V27': 0.0369695108704894,\n",
       " 'V28': 0.010984441006191,\n",
       " 'Amount': 0.0}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bac6e24d-a3e1-4654-abbc-ece8bf213413",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [json_format.ParseDict(newob, Value())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c986141a-cc54-4cf7-b839-4c04f37e3031",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [newob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8317d92a-d44f-4772-b818-4b14ae2f5174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Time': 35337,\n",
       "  'V1': 1.0928441854981998,\n",
       "  'V2': -0.0132303486713432,\n",
       "  'V3': 1.35982868199426,\n",
       "  'V4': 2.7315370965921004,\n",
       "  'V5': -0.707357349219652,\n",
       "  'V6': 0.8738370029866129,\n",
       "  'V7': -0.7961301510622031,\n",
       "  'V8': 0.437706509544851,\n",
       "  'V9': 0.39676985012996396,\n",
       "  'V10': 0.587438102569443,\n",
       "  'V11': -0.14979756231827498,\n",
       "  'V12': 0.29514781622888103,\n",
       "  'V13': -1.30382621882143,\n",
       "  'V14': -0.31782283120234495,\n",
       "  'V15': -2.03673231037199,\n",
       "  'V16': 0.376090905274179,\n",
       "  'V17': -0.30040350116459497,\n",
       "  'V18': 0.433799615590844,\n",
       "  'V19': -0.145082264348681,\n",
       "  'V20': -0.240427548108996,\n",
       "  'V21': 0.0376030733329398,\n",
       "  'V22': 0.38002620963091405,\n",
       "  'V23': -0.16764742731151097,\n",
       "  'V24': 0.0275573495476881,\n",
       "  'V25': 0.59211469704354,\n",
       "  'V26': 0.219695164116351,\n",
       "  'V27': 0.0369695108704894,\n",
       "  'V28': 0.010984441006191,\n",
       "  'Amount': 0.0}]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca96485-cfc5-4654-a890-8f1c1aa0498c",
   "metadata": {},
   "source": [
    "### Get Predictions: Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b258b39f-547c-4c60-be21-db12249c9b1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "500 {\"error\":\"500 - Internal server error\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    945\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"{\"error\":\"500 - Internal server error\"}\"\n\tdebug_error_string = \"{\"created\":\"@1667868694.847312394\",\"description\":\"Error received from peer ipv4:108.177.111.95:443\",\"file\":\"/home/conda/feedstock_root/build_artifacts/grpc-split_1656146941531/work/src/core/lib/surface/call.cc\",\"file_line\":966,\"grpc_message\":\"{\"error\":\"500 - Internal server error\"}\",\"grpc_status\":13}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2883/293583078.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, instances, parameters, timeout, use_raw_predict)\u001b[0m\n\u001b[1;32m   1543\u001b[0m                 \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m                 \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1545\u001b[0;31m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1546\u001b[0m             )\n\u001b[1;32m   1547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m         )\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalServerError\u001b[0m: 500 {\"error\":\"500 - Internal server error\"}"
     ]
    }
   ],
   "source": [
    "prediction = endpoint.predict(instances = json.dumps(instances))\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "22948432-21de-488b-afec-fa5f75f3e5b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2883/518623560.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": [
    "prediction.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4b83ebe7-5dd7-4342-8536-addcbe3cdf6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2883/1082545201.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": [
    "np.argmax(prediction.predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedbc225-b173-4839-bec8-fc1704970560",
   "metadata": {},
   "source": [
    "### Get Predictions: REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c140d317-4458-4b5b-8b48-452440904a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/request.json','w') as file:\n",
    "    file.write(json.dumps({\"instances\": [newob]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e0fee-aea7-4a7c-971f-9ff2bc9abcb3",
   "metadata": {},
   "source": [
    "thought:\n",
    "```\n",
    "-d @{DIR}/request.json \\\n",
    "-d {json.dumps(...)}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "26fcd531-30d8-4af9-890f-928fe89feec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    0.0018\n",
      "  ],\n",
      "  \"deployedModelId\": \"6706831813433622528\",\n",
      "  \"model\": \"projects/1026793852137/locations/us-central1/models/model_08_08b\",\n",
      "  \"modelDisplayName\": \"08_08b\",\n",
      "  \"modelVersionId\": \"4\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
    "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "-d @{DIR}/request.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d7979-8267-455f-9f83-9d0c1fc20bf9",
   "metadata": {},
   "source": [
    "### Get Predictions: gcloud (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "07e8d381-9624-4069-b465-30f2915f721f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
      "\u001b[1;31mERROR:\u001b[0m gcloud crashed (ContentDecodingError): ('Received response with content-encoding: gzip, gzip, but failed to decode it.', error('Error -3 while decompressing data: incorrect header check'))\n",
      "\n",
      "If you would like to report this issue, please run the following command:\n",
      "  gcloud feedback\n",
      "\n",
      "To check gcloud for common problems, please run the following command:\n",
      "  gcloud info --run-diagnostics\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ai endpoints predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --json-request={DIR}/request.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cc8d277c-c86e-4a90-9839-63f3922376e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "\u001b[1;31mERROR:\u001b[0m gcloud crashed (ContentDecodingError): ('Received response with content-encoding: gzip, gzip, but failed to decode it.', error('Error -3 while decompressing data: incorrect header check'))\n",
      "\n",
      "If you would like to report this issue, please run the following command:\n",
      "  gcloud feedback\n",
      "\n",
      "To check gcloud for common problems, please run the following command:\n",
      "  gcloud info --run-diagnostics\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai endpoints raw-predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --format=\"json\" --request=@{DIR}/request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad042de-ed86-4680-860e-352dcaf957e6",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3004b5d6-bec7-4fef-b297-ff32782af14a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
